{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "433f840f",
   "metadata": {},
   "source": [
    "## Load Data from Yfinance, NewsAPI, and Bloomberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29d4a3",
   "metadata": {},
   "source": [
    "**Load Data (Yahoo Finance)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ca684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NKE: fetched 10 raw items\n",
      "LULU: fetched 10 raw items\n",
      "ATZ.TO: fetched 10 raw items\n",
      "                                       id  \\\n",
      "0  4f8f8b55-7a15-3280-aefa-2ba5fe1c5d60-0   \n",
      "1  44127e76-4d51-3341-91f7-75a151c327de-0   \n",
      "2  d27b1692-49b5-37f9-8f7f-170607a64bc6-0   \n",
      "3  adf56cf4-fc14-38e2-8b57-4bdc4485cefa-0   \n",
      "4  45fdbd44-5798-37fc-9b78-dbf1bb62b6f0-0   \n",
      "\n",
      "                              report_id  ticker company  \\\n",
      "0  4f8f8b55-7a15-3280-aefa-2ba5fe1c5d60  ATZ.TO           \n",
      "1  44127e76-4d51-3341-91f7-75a151c327de  ATZ.TO           \n",
      "2  d27b1692-49b5-37f9-8f7f-170607a64bc6  ATZ.TO           \n",
      "3  adf56cf4-fc14-38e2-8b57-4bdc4485cefa  ATZ.TO           \n",
      "4  45fdbd44-5798-37fc-9b78-dbf1bb62b6f0  ATZ.TO           \n",
      "\n",
      "                       date    source doc_type item section_type  \\\n",
      "0 2025-12-22 13:58:54+00:00  yfinance    STORY              news   \n",
      "1 2025-12-22 12:38:14+00:00  yfinance    STORY              news   \n",
      "2 2025-12-19 19:23:11+00:00  yfinance    STORY              news   \n",
      "3 2025-12-12 12:35:50+00:00  yfinance    STORY              news   \n",
      "4 2025-12-05 17:49:06+00:00  yfinance    STORY              news   \n",
      "\n",
      "                                     section_heading  chunk_index page_start  \\\n",
      "0  The investing winners and losers that made or ...            0              \n",
      "1  TSX Value Picks Including Aritzia And Two Othe...            0              \n",
      "2  Stifel Canada Names Gildan, KITS, and Couche-T...            0              \n",
      "3  3 TSX Growth Stocks With Up To 22% Insider Own...            0              \n",
      "4  Tech Tactics: Aritzia Taps Nedap’s RFID Platfo...            0              \n",
      "\n",
      "  page_end                                               text  \\\n",
      "0           Despite turmoil from the trade war, most globa...   \n",
      "1           As 2025 draws to a close, the Canadian market ...   \n",
      "2           Stifel Canada said Friday its best ideas for C...   \n",
      "3           As we approach the end of 2025, Canadian marke...   \n",
      "4           Aritzia utilizes Nedap's RFID platform to stre...   \n",
      "\n",
      "                                         source_file  \n",
      "0  https://ca.finance.yahoo.com/news/were-investi...  \n",
      "1  https://finance.yahoo.com/news/tsx-value-picks...  \n",
      "2  https://finance.yahoo.com/news/stifel-canada-n...  \n",
      "3  https://finance.yahoo.com/news/3-tsx-growth-st...  \n",
      "4  https://sourcingjournal.com/topics/technology/...  \n",
      "\n",
      "                                            id  \\\n",
      "count                                       30   \n",
      "unique                                      30   \n",
      "top     4f8f8b55-7a15-3280-aefa-2ba5fe1c5d60-0   \n",
      "freq                                         1   \n",
      "mean                                       NaN   \n",
      "min                                        NaN   \n",
      "25%                                        NaN   \n",
      "50%                                        NaN   \n",
      "75%                                        NaN   \n",
      "max                                        NaN   \n",
      "std                                        NaN   \n",
      "\n",
      "                                   report_id  ticker company  \\\n",
      "count                                     30      30      30   \n",
      "unique                                    30       3       1   \n",
      "top     4f8f8b55-7a15-3280-aefa-2ba5fe1c5d60  ATZ.TO           \n",
      "freq                                       1      10      30   \n",
      "mean                                     NaN     NaN     NaN   \n",
      "min                                      NaN     NaN     NaN   \n",
      "25%                                      NaN     NaN     NaN   \n",
      "50%                                      NaN     NaN     NaN   \n",
      "75%                                      NaN     NaN     NaN   \n",
      "max                                      NaN     NaN     NaN   \n",
      "std                                      NaN     NaN     NaN   \n",
      "\n",
      "                                       date    source doc_type item  \\\n",
      "count                                    30        30       30   30   \n",
      "unique                                  NaN         1        1    1   \n",
      "top                                     NaN  yfinance    STORY        \n",
      "freq                                    NaN        30       30   30   \n",
      "mean    2025-12-19 20:31:13.533333504+00:00       NaN      NaN  NaN   \n",
      "min               2025-11-19 12:38:06+00:00       NaN      NaN  NaN   \n",
      "25%     2025-12-20 11:27:08.249999872+00:00       NaN      NaN  NaN   \n",
      "50%               2025-12-24 11:28:30+00:00       NaN      NaN  NaN   \n",
      "75%               2025-12-26 18:51:00+00:00       NaN      NaN  NaN   \n",
      "max               2025-12-29 01:20:00+00:00       NaN      NaN  NaN   \n",
      "std                                     NaN       NaN      NaN  NaN   \n",
      "\n",
      "       section_type                                    section_heading  \\\n",
      "count            30                                                 30   \n",
      "unique            1                                                 30   \n",
      "top            news  The investing winners and losers that made or ...   \n",
      "freq             30                                                  1   \n",
      "mean            NaN                                                NaN   \n",
      "min             NaN                                                NaN   \n",
      "25%             NaN                                                NaN   \n",
      "50%             NaN                                                NaN   \n",
      "75%             NaN                                                NaN   \n",
      "max             NaN                                                NaN   \n",
      "std             NaN                                                NaN   \n",
      "\n",
      "        chunk_index page_start page_end  \\\n",
      "count          30.0         30       30   \n",
      "unique          NaN          1        1   \n",
      "top             NaN                       \n",
      "freq            NaN         30       30   \n",
      "mean            0.0        NaN      NaN   \n",
      "min             0.0        NaN      NaN   \n",
      "25%             0.0        NaN      NaN   \n",
      "50%             0.0        NaN      NaN   \n",
      "75%             0.0        NaN      NaN   \n",
      "max             0.0        NaN      NaN   \n",
      "std             0.0        NaN      NaN   \n",
      "\n",
      "                                                     text  \\\n",
      "count                                                  30   \n",
      "unique                                                 30   \n",
      "top     Despite turmoil from the trade war, most globa...   \n",
      "freq                                                    1   \n",
      "mean                                                  NaN   \n",
      "min                                                   NaN   \n",
      "25%                                                   NaN   \n",
      "50%                                                   NaN   \n",
      "75%                                                   NaN   \n",
      "max                                                   NaN   \n",
      "std                                                   NaN   \n",
      "\n",
      "                                              source_file  \n",
      "count                                                  30  \n",
      "unique                                                 30  \n",
      "top     https://ca.finance.yahoo.com/news/were-investi...  \n",
      "freq                                                    1  \n",
      "mean                                                  NaN  \n",
      "min                                                   NaN  \n",
      "25%                                                   NaN  \n",
      "50%                                                   NaN  \n",
      "75%                                                   NaN  \n",
      "max                                                   NaN  \n",
      "std                                                   NaN  \n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, UTC\n",
    "import time\n",
    "\n",
    "CANONICAL_FIELDS = [\n",
    "    \"id\",\n",
    "    \"report_id\",\n",
    "    \"ticker\",\n",
    "    \"company\",\n",
    "    \"date\",\n",
    "    \"source\",\n",
    "    \"doc_type\",\n",
    "    \"item\",\n",
    "    \"section_type\",\n",
    "    \"section_heading\",\n",
    "    \"chunk_index\",\n",
    "    \"page_start\",\n",
    "    \"page_end\",\n",
    "    \"text\",\n",
    "    \"source_file\",\n",
    "]\n",
    "\n",
    "\n",
    "def make_row(*, report_id, text, chunk_index, source, source_file, ticker=None, company=None, date=None, doc_type=None, item=None, section_type=None, section_heading=None, page_start=None, page_end=None):\n",
    "    return {\n",
    "        \"id\": f\"{report_id}-{chunk_index}\",\n",
    "        \"report_id\": report_id,\n",
    "        \"ticker\": ticker or \"\",\n",
    "        \"company\": company or \"\",\n",
    "        \"date\": date or \"\",\n",
    "        \"source\": source,\n",
    "        \"doc_type\": doc_type or \"\",\n",
    "        \"item\": item or \"\",\n",
    "        \"section_type\": section_type or \"\",\n",
    "        \"section_heading\": section_heading or \"\",\n",
    "        \"chunk_index\": chunk_index,\n",
    "        \"page_start\": page_start or \"\",\n",
    "        \"page_end\": page_end or \"\",\n",
    "        \"text\": (text or \"\").strip(),\n",
    "        \"source_file\": source_file,\n",
    "    }\n",
    "\n",
    "# Tickers to analyze\n",
    "TICKERS = [\"NKE\", \"LULU\", \"ATZ.TO\"]\n",
    "YF_MAX_ITEMS = 10  # yfinance often returns ~10\n",
    "LOOKBACK_DAYS = 365\n",
    "\n",
    "\n",
    "def extract_article(item: dict, ticker: str) -> dict:\n",
    "    content = item.get(\"content\", {}) or {}\n",
    "\n",
    "    # Published time: providerPublishTime (unix) or content pubDate/displayTime\n",
    "    published_dt = None\n",
    "    ts = item.get(\"providerPublishTime\")\n",
    "    if ts:\n",
    "        try:\n",
    "            published_dt = datetime.fromtimestamp(ts, tz=UTC)\n",
    "        except Exception:\n",
    "            published_dt = None\n",
    "    if published_dt is None:\n",
    "        pub_iso = content.get(\"pubDate\") or content.get(\"displayTime\")\n",
    "        if pub_iso:\n",
    "            published_dt = pd.to_datetime(pub_iso, errors=\"coerce\", utc=True)\n",
    "\n",
    "    link = (\n",
    "        item.get(\"link\")\n",
    "        or (item.get(\"canonicalUrl\") or {}).get(\"url\")\n",
    "        or (item.get(\"clickThroughUrl\") or {}).get(\"url\")\n",
    "        or (content.get(\"canonicalUrl\") or {}).get(\"url\")\n",
    "        or (content.get(\"clickThroughUrl\") or {}).get(\"url\")\n",
    "    )\n",
    "    report_id = item.get(\"id\") or item.get(\"uuid\") or f\"{ticker}-{int(time.time())}\"\n",
    "    publisher = (item.get(\"publisher\") or (content.get(\"provider\") or {}).get(\"displayName\") or \"\").strip()\n",
    "    doc_type = (item.get(\"type\") or content.get(\"contentType\") or \"news\").strip()\n",
    "    heading = (content.get(\"title\") or item.get(\"title\") or \"\").strip()\n",
    "    text = (content.get(\"summary\") or content.get(\"description\") or item.get(\"summary\") or heading).strip()\n",
    "\n",
    "    return make_row(\n",
    "        report_id=report_id,\n",
    "        text=text,\n",
    "        chunk_index=0,\n",
    "        source=\"yfinance\",\n",
    "        source_file=link or \"\",\n",
    "        ticker=ticker,\n",
    "        company=\"\",\n",
    "        date=str(published_dt) if published_dt is not None else \"\",\n",
    "        doc_type=doc_type,\n",
    "        section_type=\"news\",\n",
    "        section_heading=heading,\n",
    "        page_start=\"\",\n",
    "        page_end=\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "rows = []\n",
    "for tic in TICKERS:\n",
    "    raw_news = (yf.Ticker(tic).news or [])[:YF_MAX_ITEMS]\n",
    "    rows.extend([extract_article(item, tic) for item in raw_news])\n",
    "    print(f\"{tic}: fetched {len(raw_news)} raw items\")\n",
    "    time.sleep(1)\n",
    "\n",
    "# Build dataframe\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.reindex(columns=CANONICAL_FIELDS)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\", utc=True)\n",
    "    cutoff = pd.Timestamp.now(tz=\"UTC\") - pd.Timedelta(days=LOOKBACK_DAYS)\n",
    "    df = df[df[\"date\"].isna() | (df[\"date\"] >= cutoff)]\n",
    "    df = df.drop_duplicates(subset=[\"section_heading\", \"source_file\"])\n",
    "    df = df.sort_values([\"ticker\", \"date\"], ascending=[True, False]).reset_index(drop=True)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=CANONICAL_FIELDS)\n",
    "\n",
    "print(df.head())\n",
    "print()\n",
    "print(df.describe(include=\"all\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72945253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to ./processed_data/financial_news_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = \"./processed_data/financial_news_dataset.csv\"  # optional export\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(f\"Data exported to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfa9a25",
   "metadata": {},
   "source": [
    "**Import Data From News API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2bfb294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "keywords = {\n",
    "    \"nike\": [\"nke\",\"NKE\"],\n",
    "    \"atz\": [\"ATZ\", \"atz\", \"atz.co\",\"ATZ.CO\"],\n",
    "    \"lulu\": [\"lulu\", \"LULU\"]\n",
    "}\n",
    "\n",
    "DATE = '2025-12-01'\n",
    "\n",
    "api_key= os.getenv('NEWS_API_KEY')\n",
    "\n",
    "# Init\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcef422",
   "metadata": {},
   "source": [
    "**Export NewsAPI articles to CSV**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1686f1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 157 rows to processed_data/newsapi_articles.csv\n",
      "                                   id                         report_id  \\\n",
      "0  7ac88f377541dfa1a4647f81055416b1-0  7ac88f377541dfa1a4647f81055416b1   \n",
      "1  d0e260880c6c12f6e784a2c545307eff-0  d0e260880c6c12f6e784a2c545307eff   \n",
      "2  8298c16f954431dcb0da138467024fdd-0  8298c16f954431dcb0da138467024fdd   \n",
      "3  7cd991eba9bad7579b584ca9daa2aad3-0  7cd991eba9bad7579b584ca9daa2aad3   \n",
      "4  777093cbbccf2c9e9cba482a8cadb43d-0  777093cbbccf2c9e9cba482a8cadb43d   \n",
      "\n",
      "  ticker company                  date   source doc_type item section_type  \\\n",
      "0    NKE    nike  2025-12-05T22:06:20Z  newsapi     news              news   \n",
      "1    NKE    nike  2025-12-23T12:16:21Z  newsapi     news              news   \n",
      "2    NKE    nike  2025-12-17T18:47:56Z  newsapi     news              news   \n",
      "3    NKE    nike  2025-12-25T15:36:47Z  newsapi     news              news   \n",
      "4    NKE    nike  2025-12-22T17:01:51Z  newsapi     news              news   \n",
      "\n",
      "                                     section_heading  chunk_index page_start  \\\n",
      "0               NIKE, Inc. (NKE): A Bear Case Theory            0              \n",
      "1               Market Digest: HRL, KR, MU, NKE, PCG            0              \n",
      "2  Guggenheim Initiates Nike (NKE) at Buy on Marg...            0              \n",
      "3      Nike (NKE) Jumps 4.6% as Tim Cook Hikes Stake            0              \n",
      "4  Earnings Disappointment Sends Nike Stock Below...            0              \n",
      "\n",
      "  page_end                                               text  \\\n",
      "0           We came across a bearish thesis on NIKE, Inc. ...   \n",
      "1                                  Oops, something went wrong   \n",
      "2           NIKE, Inc. (NYSE:NKE) is included among the 12...   \n",
      "3           We recently published 10 Stocks Lighting Up Ma...   \n",
      "4           Nike (NKE) shares crashed over 10% on Dec. 19 ...   \n",
      "\n",
      "                                         source_file  \n",
      "0  https://finance.yahoo.com/news/nike-inc-nke-be...  \n",
      "1  https://finance.yahoo.com/research/reports/ARG...  \n",
      "2  https://finance.yahoo.com/news/guggenheim-init...  \n",
      "3  https://finance.yahoo.com/news/nike-nke-jumps-...  \n",
      "4  https://www.barchart.com/story/news/36746721/e...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "\n",
    "CANONICAL_FIELDS = [\n",
    "    \"id\",\n",
    "    \"report_id\",\n",
    "    \"ticker\",\n",
    "    \"company\",\n",
    "    \"date\",\n",
    "    \"source\",\n",
    "    \"doc_type\",\n",
    "    \"item\",\n",
    "    \"section_type\",\n",
    "    \"section_heading\",\n",
    "    \"chunk_index\",\n",
    "    \"page_start\",\n",
    "    \"page_end\",\n",
    "    \"text\",\n",
    "    \"source_file\",\n",
    "]\n",
    "\n",
    "\n",
    "def make_row(*, report_id, text, chunk_index, source, source_file, ticker=None, company=None, date=None, doc_type=None, item=None, section_type=None, section_heading=None, page_start=None, page_end=None):\n",
    "    return {\n",
    "        \"id\": f\"{report_id}-{chunk_index}\",\n",
    "        \"report_id\": report_id,\n",
    "        \"ticker\": ticker or \"\",\n",
    "        \"company\": company or \"\",\n",
    "        \"date\": date or \"\",\n",
    "        \"source\": source,\n",
    "        \"doc_type\": doc_type or \"\",\n",
    "        \"item\": item or \"\",\n",
    "        \"section_type\": section_type or \"\",\n",
    "        \"section_heading\": section_heading or \"\",\n",
    "        \"chunk_index\": chunk_index,\n",
    "        \"page_start\": page_start or \"\",\n",
    "        \"page_end\": page_end or \"\",\n",
    "        \"text\": (text or \"\").strip(),\n",
    "        \"source_file\": source_file,\n",
    "    }\n",
    "\n",
    "\n",
    "def stable_id(text: str, url: str) -> str:\n",
    "    basis = (url or text or \"\").encode(\"utf-8\")\n",
    "    return hashlib.md5(basis, usedforsecurity=False).hexdigest()\n",
    "\n",
    "\n",
    "def fetch_news_articles(keywords, start_date):\n",
    "    rows = []\n",
    "    for kw, words in keywords.items():\n",
    "        query = \" OR \".join(words)\n",
    "        resp = newsapi.get_everything(\n",
    "            q=query,\n",
    "            from_param=start_date,\n",
    "            language=\"en\",\n",
    "            sort_by=\"relevancy\",\n",
    "            page=1,\n",
    "            page_size=100,\n",
    "        )\n",
    "        ticker = \"\"\n",
    "        if kw == \"nike\":\n",
    "            ticker = \"NKE\"\n",
    "        if kw == \"atz\":\n",
    "            ticker = \"ATZ\"\n",
    "        if kw == \"lulu\":\n",
    "            ticker = \"LULU\"\n",
    "\n",
    "        for art in resp.get(\"articles\", []):\n",
    "            title = art.get(\"title\") or \"\"\n",
    "            text = (art.get(\"content\") or art.get(\"description\") or title).strip()\n",
    "            if not text:\n",
    "                continue\n",
    "            url = art.get(\"url\") or \"\"\n",
    "            rid = stable_id(title, url)\n",
    "            rows.append(\n",
    "                make_row(\n",
    "                    report_id=rid,\n",
    "                    text=text,\n",
    "                    chunk_index=0,\n",
    "                    source=\"newsapi\",\n",
    "                    source_file=url,\n",
    "                    ticker=ticker,\n",
    "                    company=kw,\n",
    "                    date=art.get(\"publishedAt\") or \"\",\n",
    "                    doc_type=\"news\",\n",
    "                    section_type=\"news\",\n",
    "                    section_heading=title,\n",
    "                )\n",
    "            )\n",
    "    return pd.DataFrame(rows, columns=CANONICAL_FIELDS)\n",
    "\n",
    "\n",
    "df_news = fetch_news_articles(keywords, DATE)\n",
    "\n",
    "Path(\"processed_data\").mkdir(parents=True, exist_ok=True)\n",
    "output_path = \"processed_data/newsapi_articles.csv\"\n",
    "df_news.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(df_news)} rows to {output_path}\")\n",
    "print(df_news.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9375246a",
   "metadata": {},
   "source": [
    "**Analyzing Equity Research Reports from Bloomberg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36586d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDone in pdf_section_extractor.py\\n\\nPulls thesis/growth/risk/valuation/earnings blocks using simple\\nheading heuristics, then optionally chunks text for BERT-friendly input.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Done in pdf_section_extractor.py\n",
    "\n",
    "Pulls thesis/growth/risk/valuation/earnings blocks using simple\n",
    "heading heuristics, then optionally chunks text for BERT-friendly input.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff4a87",
   "metadata": {},
   "source": [
    "**SEC + TSEC Filings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6616f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 8K filings for Nike and Lululemon (tickers \"nke\" and \"lulu\")\\nmy_filings_8k = filings(cik_lookup=[\"nke\",\"lulu\"],\\n                     filing_type=FilingType.FILING_8K,\\n                     user_agent=\"Simon Kurono (simonkurono@gmail.com)\")\\n\\nmy_filings_8k.save(\\'./nlp/raw_data/sec_filings_8k\\')\\n\\n# 10Q filings for Nike and Lululemon (tickers \"nke\" and \"lulu\")\\nmy_filings_8k = filings(cik_lookup=[\"nke\",\"lulu\"],\\n                     filing_type=FilingType.FILING_10Q,\\n                     user_agent=\"Simon Kurono (simonkurono@gmail.com)\")\\n\\nmy_filings_8k.save(\\'./nlp/raw_data/sec_filings_10q\\')\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from secedgar import filings, FilingType\n",
    "\n",
    "\"\"\"\n",
    "# 8K filings for Nike and Lululemon (tickers \"nke\" and \"lulu\")\n",
    "my_filings_8k = filings(cik_lookup=[\"nke\",\"lulu\"],\n",
    "                     filing_type=FilingType.FILING_8K,\n",
    "                     user_agent=\"Simon Kurono (simonkurono@gmail.com)\")\n",
    "\n",
    "my_filings_8k.save('./nlp/raw_data/sec_filings_8k')\n",
    "\n",
    "# 10Q filings for Nike and Lululemon (tickers \"nke\" and \"lulu\")\n",
    "my_filings_8k = filings(cik_lookup=[\"nke\",\"lulu\"],\n",
    "                     filing_type=FilingType.FILING_10Q,\n",
    "                     user_agent=\"Simon Kurono (simonkurono@gmail.com)\")\n",
    "\n",
    "my_filings_8k.save('./nlp/raw_data/sec_filings_10q')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb63ba94",
   "metadata": {},
   "source": [
    "**Compile All Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a90d267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skurono\\Desktop\\SCMC\\scmc-2025\\nlp\n",
      "                          id                report_id ticker  company  date  \\\n",
      "0  Aritzia-Inc-Q1-2025-MDA-0  Aritzia-Inc-Q1-2025-MDA    ATZ      NaN   NaN   \n",
      "1  Aritzia-Inc-Q1-2025-MDA-1  Aritzia-Inc-Q1-2025-MDA    ATZ      NaN   NaN   \n",
      "2  Aritzia-Inc-Q1-2025-MDA-2  Aritzia-Inc-Q1-2025-MDA    ATZ      NaN   NaN   \n",
      "3  Aritzia-Inc-Q1-2025-MDA-3  Aritzia-Inc-Q1-2025-MDA    ATZ      NaN   NaN   \n",
      "4  Aritzia-Inc-Q1-2025-MDA-4  Aritzia-Inc-Q1-2025-MDA    ATZ      NaN   NaN   \n",
      "\n",
      "       source doc_type  item section_type  section_heading  chunk_index  \\\n",
      "0  mda_canada     md&a   NaN         md&a              NaN            0   \n",
      "1  mda_canada     md&a   NaN         md&a              NaN            1   \n",
      "2  mda_canada     md&a   NaN         md&a              NaN            2   \n",
      "3  mda_canada     md&a   NaN         md&a              NaN            3   \n",
      "4  mda_canada     md&a   NaN         md&a              NaN            4   \n",
      "\n",
      "   page_start  page_end                                               text  \\\n",
      "0           1         3  First Quarter Ended June 2, 2024 July 11, 2024...   \n",
      "1           3         3  BASIS OF PRESENTATION Our audited annual conso...   \n",
      "2           3         4  Our Approach Aritzia means style, not trend, a...   \n",
      "3           4         4  Q1 2025 For Q1 2025, compared to Q1 2024: – Ne...   \n",
      "4           4         5  See the sections below entitled “How We Assess...   \n",
      "\n",
      "                                         source_file  \n",
      "0  nlp\\raw_data\\sec_can\\atz_q_mda\\Aritzia-Inc-Q1-...  \n",
      "1  nlp\\raw_data\\sec_can\\atz_q_mda\\Aritzia-Inc-Q1-...  \n",
      "2  nlp\\raw_data\\sec_can\\atz_q_mda\\Aritzia-Inc-Q1-...  \n",
      "3  nlp\\raw_data\\sec_can\\atz_q_mda\\Aritzia-Inc-Q1-...  \n",
      "4  nlp\\raw_data\\sec_can\\atz_q_mda\\Aritzia-Inc-Q1-...  \n",
      "       company  date  item  section_heading  chunk_index  page_start  \\\n",
      "count      0.0   0.0   0.0              0.0   279.000000  279.000000   \n",
      "mean       NaN   NaN   NaN              NaN    23.125448   14.365591   \n",
      "std        NaN   NaN   NaN              NaN    14.057514    7.395485   \n",
      "min        NaN   NaN   NaN              NaN     0.000000    1.000000   \n",
      "25%        NaN   NaN   NaN              NaN    11.000000    8.000000   \n",
      "50%        NaN   NaN   NaN              NaN    23.000000   14.000000   \n",
      "75%        NaN   NaN   NaN              NaN    34.000000   20.000000   \n",
      "max        NaN   NaN   NaN              NaN    53.000000   30.000000   \n",
      "\n",
      "         page_end  \n",
      "count  279.000000  \n",
      "mean    14.810036  \n",
      "std      7.374595  \n",
      "min      2.000000  \n",
      "25%      9.000000  \n",
      "50%     15.000000  \n",
      "75%     21.000000  \n",
      "max     30.000000  \n",
      "                                       id  \\\n",
      "0  4f8f8b55-7a15-3280-aefa-2ba5fe1c5d60-0   \n",
      "1  44127e76-4d51-3341-91f7-75a151c327de-0   \n",
      "2  d27b1692-49b5-37f9-8f7f-170607a64bc6-0   \n",
      "3  adf56cf4-fc14-38e2-8b57-4bdc4485cefa-0   \n",
      "4  45fdbd44-5798-37fc-9b78-dbf1bb62b6f0-0   \n",
      "\n",
      "                              report_id  ticker  company  \\\n",
      "0  4f8f8b55-7a15-3280-aefa-2ba5fe1c5d60  ATZ.TO      NaN   \n",
      "1  44127e76-4d51-3341-91f7-75a151c327de  ATZ.TO      NaN   \n",
      "2  d27b1692-49b5-37f9-8f7f-170607a64bc6  ATZ.TO      NaN   \n",
      "3  adf56cf4-fc14-38e2-8b57-4bdc4485cefa  ATZ.TO      NaN   \n",
      "4  45fdbd44-5798-37fc-9b78-dbf1bb62b6f0  ATZ.TO      NaN   \n",
      "\n",
      "                        date    source doc_type  item section_type  \\\n",
      "0  2025-12-22 13:58:54+00:00  yfinance    STORY   NaN         news   \n",
      "1  2025-12-22 12:38:14+00:00  yfinance    STORY   NaN         news   \n",
      "2  2025-12-19 19:23:11+00:00  yfinance    STORY   NaN         news   \n",
      "3  2025-12-12 12:35:50+00:00  yfinance    STORY   NaN         news   \n",
      "4  2025-12-05 17:49:06+00:00  yfinance    STORY   NaN         news   \n",
      "\n",
      "                                     section_heading  chunk_index  page_start  \\\n",
      "0  The investing winners and losers that made or ...            0         NaN   \n",
      "1  TSX Value Picks Including Aritzia And Two Othe...            0         NaN   \n",
      "2  Stifel Canada Names Gildan, KITS, and Couche-T...            0         NaN   \n",
      "3  3 TSX Growth Stocks With Up To 22% Insider Own...            0         NaN   \n",
      "4  Tech Tactics: Aritzia Taps Nedap’s RFID Platfo...            0         NaN   \n",
      "\n",
      "   page_end                                               text  \\\n",
      "0       NaN  Despite turmoil from the trade war, most globa...   \n",
      "1       NaN  As 2025 draws to a close, the Canadian market ...   \n",
      "2       NaN  Stifel Canada said Friday its best ideas for C...   \n",
      "3       NaN  As we approach the end of 2025, Canadian marke...   \n",
      "4       NaN  Aritzia utilizes Nedap's RFID platform to stre...   \n",
      "\n",
      "                                         source_file  \n",
      "0  https://ca.finance.yahoo.com/news/were-investi...  \n",
      "1  https://finance.yahoo.com/news/tsx-value-picks...  \n",
      "2  https://finance.yahoo.com/news/stifel-canada-n...  \n",
      "3  https://finance.yahoo.com/news/3-tsx-growth-st...  \n",
      "4  https://sourcingjournal.com/topics/technology/...  \n",
      "       company  item  chunk_index  page_start  page_end\n",
      "count      0.0   0.0         30.0         0.0       0.0\n",
      "mean       NaN   NaN          0.0         NaN       NaN\n",
      "std        NaN   NaN          0.0         NaN       NaN\n",
      "min        NaN   NaN          0.0         NaN       NaN\n",
      "25%        NaN   NaN          0.0         NaN       NaN\n",
      "50%        NaN   NaN          0.0         NaN       NaN\n",
      "75%        NaN   NaN          0.0         NaN       NaN\n",
      "max        NaN   NaN          0.0         NaN       NaN\n",
      "   7ac88f377541dfa1a4647f81055416b1  NKE Unnamed: 2  2025-12-05T22:06:20Z  \\\n",
      "0  8298c16f954431dcb0da138467024fdd  NKE        NaN  2025-12-17T18:47:56Z   \n",
      "1  7cd991eba9bad7579b584ca9daa2aad3  NKE        NaN  2025-12-25T15:36:47Z   \n",
      "2  777093cbbccf2c9e9cba482a8cadb43d  NKE        NaN  2025-12-22T17:01:51Z   \n",
      "3  7e8e76df9eabd632df3989fdf36f7b65  NKE        NaN  2025-12-07T15:00:02Z   \n",
      "4  fca45a1010c5d7b93d7c6143e7b0e627  NKE        NaN  2025-12-21T15:44:50Z   \n",
      "\n",
      "   news  news_article  Unnamed: 6 news.1  \\\n",
      "0  news  news_article         NaN   news   \n",
      "1  news  news_article         NaN   news   \n",
      "2  news  news_article         NaN   news   \n",
      "3  news  news_article         NaN   news   \n",
      "4  news  news_article         NaN   news   \n",
      "\n",
      "                NIKE, Inc. (NKE): A Bear Case Theory  0  Unnamed: 10  \\\n",
      "0  Guggenheim Initiates Nike (NKE) at Buy on Marg...  0          NaN   \n",
      "1      Nike (NKE) Jumps 4.6% as Tim Cook Hikes Stake  0          NaN   \n",
      "2  Earnings Disappointment Sends Nike Stock Below...  0          NaN   \n",
      "3  As Nike Shakes Up Its C-Suite, Should You Buy,...  0          NaN   \n",
      "4               Jim Cramer Highlights Nike Struggles  0          NaN   \n",
      "\n",
      "   Unnamed: 11  \\\n",
      "0          NaN   \n",
      "1          NaN   \n",
      "2          NaN   \n",
      "3          NaN   \n",
      "4          NaN   \n",
      "\n",
      "  We came across a bearish thesis on NIKE, Inc. on Uncle Stock Notes’s Substack. In this article, we will summarize the bulls’ thesis on NKE. NIKE, Inc.'s share was trading at $65.39 as of December 1st. NKE’s trailing and forward P/E were 33.53 and 40.32, respectively according to Yahoo Finance.\\nPixabay/Public Domain\\nNike’s Q1 FY2026 results underscore a company in transition, struggling to find footing amid mounting competitive and operational pressures. While total revenue rose a modest 1% year-over-year to $11.7 billion, the composition of growth revealed deeper issues—North American revenue declined 3%, and Nike Direct sales fell 4%, undermining years of effort to build a high-margin D2C model. Instead, wholesale sales grew 7%, signaling a tactical reversal as Nike leans on retail partners to offset direct-channel weakness. This shift, though necessary in the short term, highlights the strain on Nike’s once-vaunted brand power and consumer connection.\\nGross margin deterioration was the most alarming signal, plunging 320 basis points to 42.2% due to elevated product costs, unfavorable currency effects, and widespread discounting to clear excess inventory. The erosion of pricing power underscores the weakening of Nike’s brand premium—a critical concern for a company long defined by its aspirational positioning. Management’s “Win Now” initiative, intended to reignite core categories such as running and basketball, remains in early stages, with little evidence yet of meaningful financial impact.\\nRegionally, softness in Greater China and continued weakness in North America offset moderate growth in EMEA and APLA. The company’s reluctance to issue guidance reflects uncertainty about the near-term outlook, as inventory challenges, macro headwinds, and rising competition from brands like Hoka and On weigh on visibility. Though Nike’s global scale, supply chain strength, and distribution network remain significant advantages, the quarter revealed a brand in search of renewed identity and strategic clarity. For now, sentiment skews bearish as the company’s transition from stagnation to sustainable growth remains incomplete.\\nPreviously, we covered a bullish thesis on NIKE, Inc. (NKE) by Any_Chocolate6194 in May 2025, which highlighted the company’s brand dominance, leadership renewal, and long-term recovery potential. The company’s stock price has appreciated by approximately 5.33% since our coverage. This is because the recovery thesis has yet to fully play out. Uncle Stock Notes shares a contrarian but emphasizes near-term execution and D2C challenges.  \\\n",
      "0  NIKE, Inc. (NYSE:NKE) is included among the 12...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "1  We recently published 10 Stocks Lighting Up Ma...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "2  Nike (NKE) shares crashed over 10% on Dec. 19 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "3  NIKE (NKE), the global icon of sport and stree...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "4  NIKE, Inc. (NYSE:NKE) is one of the tech and c...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "\n",
      "  https://finance.yahoo.com/news/nike-inc-nke-bear-case-220620409.html  \n",
      "0  https://finance.yahoo.com/news/guggenheim-init...                    \n",
      "1  https://finance.yahoo.com/news/nike-nke-jumps-...                    \n",
      "2  https://www.barchart.com/story/news/36746721/e...                    \n",
      "3  https://www.barchart.com/story/news/36497105/a...                    \n",
      "4  https://finance.yahoo.com/news/jim-cramer-high...                    \n",
      "       Unnamed: 6      0  Unnamed: 10  Unnamed: 11\n",
      "count         0.0  155.0          0.0          0.0\n",
      "mean          NaN    0.0          NaN          NaN\n",
      "std           NaN    0.0          NaN          NaN\n",
      "min           NaN    0.0          NaN          NaN\n",
      "25%           NaN    0.0          NaN          NaN\n",
      "50%           NaN    0.0          NaN          NaN\n",
      "75%           NaN    0.0          NaN          NaN\n",
      "max           NaN    0.0          NaN          NaN\n",
      "                                                  id  \\\n",
      "0  20231103_Digital_Sales_Poised_to_Double_by_202...   \n",
      "1  20231103_Digital_Sales_Poised_to_Double_by_202...   \n",
      "2  20231103_Digital_Sales_Poised_to_Double_by_202...   \n",
      "3  20231103_Digital_Sales_Poised_to_Double_by_202...   \n",
      "4  20231103_Digital_Sales_Poised_to_Double_by_202...   \n",
      "\n",
      "                                           report_id ticker  company  date  \\\n",
      "0  20231103_Digital_Sales_Poised_to_Double_by_202...    ATZ      NaN   NaN   \n",
      "1  20231103_Digital_Sales_Poised_to_Double_by_202...    ATZ      NaN   NaN   \n",
      "2  20231103_Digital_Sales_Poised_to_Double_by_202...    ATZ      NaN   NaN   \n",
      "3  20231103_Digital_Sales_Poised_to_Double_by_202...    ATZ      NaN   NaN   \n",
      "4  20231103_Digital_Sales_Poised_to_Double_by_202...    ATZ      NaN   NaN   \n",
      "\n",
      "      source       doc_type  item section_type  \\\n",
      "0  bloomberg  research_note   NaN       thesis   \n",
      "1  bloomberg  research_note   NaN       growth   \n",
      "2  bloomberg  research_note   NaN       growth   \n",
      "3  bloomberg  research_note   NaN       growth   \n",
      "4  bloomberg  research_note   NaN       growth   \n",
      "\n",
      "                                     section_heading  chunk_index  page_start  \\\n",
      "0  Aritzia Sales Could Double on US Expansion, Gr...            0           1   \n",
      "1    1. Setting Up Significant White Space Potential            1           1   \n",
      "2  Private Brands Are 95% of Sales: Wilfred 28%, ...            2           1   \n",
      "3    2. Margin Can Increase at Least 500 Bps in 2024            3           1   \n",
      "4  3. Digital Sales Poised to Double by 2027 (Cor...            4           2   \n",
      "\n",
      "   page_end                                               text  \\\n",
      "0         1  ( bloomberg intelligence ) - - aritzia has a l...   \n",
      "1         1  aritzia's plan to lift revenue 60 % to c $ 3. ...   \n",
      "2         1  26 %, super puff 7 - 8 %, denim forum, sunday ...   \n",
      "3         2  aritzia's ebitda margin could expand by 500 bp...   \n",
      "4         2  aritzia's c $ 800 million of digital sales cou...   \n",
      "\n",
      "                                         source_file  \n",
      "0  nlp\\raw_data\\bloomberg\\atz_research\\20231103_D...  \n",
      "1  nlp\\raw_data\\bloomberg\\atz_research\\20231103_D...  \n",
      "2  nlp\\raw_data\\bloomberg\\atz_research\\20231103_D...  \n",
      "3  nlp\\raw_data\\bloomberg\\atz_research\\20231103_D...  \n",
      "4  nlp\\raw_data\\bloomberg\\atz_research\\20231103_D...  \n",
      "       company  date  item  chunk_index   page_start     page_end\n",
      "count      0.0   0.0   0.0  3178.000000  3178.000000  3178.000000\n",
      "mean       NaN   NaN   NaN    24.095972     9.231907    10.274386\n",
      "std        NaN   NaN   NaN    21.194898     9.563401    10.006431\n",
      "min        NaN   NaN   NaN     0.000000     1.000000     1.000000\n",
      "25%        NaN   NaN   NaN     7.000000     3.000000     3.000000\n",
      "50%        NaN   NaN   NaN    19.000000     6.000000     7.000000\n",
      "75%        NaN   NaN   NaN    35.000000    12.000000    14.000000\n",
      "max        NaN   NaN   NaN   113.000000    63.000000    67.000000\n",
      "                                                  id  \\\n",
      "0  Aritzia_-_NCIB_2025_-_Announcement_Press_Relea...   \n",
      "1  Aritzia_-_NCIB_2025_-_Announcement_Press_Relea...   \n",
      "2  Aritzia_-_NCIB_2025_-_Announcement_Press_Relea...   \n",
      "3  Aritzia_-_NCIB_2025_-_Announcement_Press_Relea...   \n",
      "4  Aritzia_-_NCIB_2025_-_Announcement_Press_Relea...   \n",
      "\n",
      "                                          report_id ticker       company  \\\n",
      "0  Aritzia_-_NCIB_2025_-_Announcement_Press_Release    ATZ  Aritzia Inc.   \n",
      "1  Aritzia_-_NCIB_2025_-_Announcement_Press_Release    ATZ  Aritzia Inc.   \n",
      "2  Aritzia_-_NCIB_2025_-_Announcement_Press_Release    ATZ  Aritzia Inc.   \n",
      "3  Aritzia_-_NCIB_2025_-_Announcement_Press_Release    ATZ  Aritzia Inc.   \n",
      "4  Aritzia_-_NCIB_2025_-_Announcement_Press_Release    ATZ  Aritzia Inc.   \n",
      "\n",
      "   date         source           doc_type  item     section_type  \\\n",
      "0   NaN  press_release  ncib_announcement   NaN  capital_returns   \n",
      "1   NaN  press_release  ncib_announcement   NaN  capital_returns   \n",
      "2   NaN  press_release  ncib_announcement   NaN      boilerplate   \n",
      "3   NaN  press_release  ncib_announcement   NaN            other   \n",
      "4   NaN  press_release  ncib_announcement   NaN      boilerplate   \n",
      "\n",
      "                              section_heading  chunk_index  page_start  \\\n",
      "0  ARITZIA ANNOUNCES NORMAL COURSE ISSUER BID            0           1   \n",
      "1  ARITZIA ANNOUNCES NORMAL COURSE ISSUER BID            1           1   \n",
      "2                               About Aritzia            0           1   \n",
      "3                                Our Approach            0           1   \n",
      "4                 Forward-looking Information            0           2   \n",
      "\n",
      "   page_end                                               text  \\\n",
      "0         1  VANCOUVER, May 5, 2025 – Aritzia Inc. (\"Aritzi...   \n",
      "1         1  As at March 2, 2025, the Company had approxima...   \n",
      "2         1  Aritzia is a design house with an innovative g...   \n",
      "3         2  Aritzia means style, not trend, and quality ov...   \n",
      "4         3  Certain statements made in this press release ...   \n",
      "\n",
      "                                         source_file  \n",
      "0  nlp\\raw_data\\sec_can\\news_releases\\Aritzia_-_N...  \n",
      "1  nlp\\raw_data\\sec_can\\news_releases\\Aritzia_-_N...  \n",
      "2  nlp\\raw_data\\sec_can\\news_releases\\Aritzia_-_N...  \n",
      "3  nlp\\raw_data\\sec_can\\news_releases\\Aritzia_-_N...  \n",
      "4  nlp\\raw_data\\sec_can\\news_releases\\Aritzia_-_N...  \n",
      "       date  item  chunk_index  page_start    page_end\n",
      "count   0.0   0.0   189.000000  189.000000  189.000000\n",
      "mean    NaN   NaN     1.095238    5.920635    6.486772\n",
      "std     NaN   NaN     2.096458    3.985218    3.883419\n",
      "min     NaN   NaN     0.000000    1.000000    1.000000\n",
      "25%     NaN   NaN     0.000000    2.000000    3.000000\n",
      "50%     NaN   NaN     0.000000    5.000000    7.000000\n",
      "75%     NaN   NaN     1.000000    9.000000   10.000000\n",
      "max     NaN   NaN     9.000000   14.000000   14.000000\n",
      "                       id             report_id ticker  company        date  \\\n",
      "0  0000909567-07-001490-0  0000909567-07-001490    TXT      NaN  2007-11-29   \n",
      "1  0000909567-08-000377-0  0000909567-08-000377    TXT      NaN  2008-04-02   \n",
      "2  0000909567-08-001002-0  0000909567-08-001002    TXT      NaN  2008-09-11   \n",
      "3  0000909567-08-001269-0  0000909567-08-001269    TXT      NaN  2008-12-11   \n",
      "4  0000945234-07-000574-0  0000945234-07-000574    TXT      NaN  2007-09-10   \n",
      "\n",
      "  source doc_type  item section_type  \\\n",
      "0    sec      8-K  2.02      results   \n",
      "1    sec      8-K  2.02      results   \n",
      "2    sec      8-K  2.02      results   \n",
      "3    sec      8-K  2.02      results   \n",
      "4    sec      8-K  2.02      results   \n",
      "\n",
      "                                     section_heading  chunk_index  page_start  \\\n",
      "0  Results of Operations and Financial Condition ...            0         NaN   \n",
      "1  Results of Operations and Financial Condition ...            0         NaN   \n",
      "2  Results of Operations and Financial Condition ...            0         NaN   \n",
      "3  Results of Operations and Financial Condition ...            0         NaN   \n",
      "4  Results of Operations and Financial Condition ...            0         NaN   \n",
      "\n",
      "   page_end                                               text  \\\n",
      "0       NaN  On November 29, 2007, lululemon athletica inc....   \n",
      "1       NaN  In\\naddition to reporting financial results in...   \n",
      "2       NaN  On September 11, 2008, lululemon athletica inc...   \n",
      "3       NaN  On December 11, 2008, lululemon athletica inc....   \n",
      "4       NaN  On September 10, 2007, lululemon athletica inc...   \n",
      "\n",
      "                                         source_file  \n",
      "0  nlp\\raw_data\\sec_filings_8k\\lulu\\8-K\\000090956...  \n",
      "1  nlp\\raw_data\\sec_filings_8k\\lulu\\8-K\\000090956...  \n",
      "2  nlp\\raw_data\\sec_filings_8k\\lulu\\8-K\\000090956...  \n",
      "3  nlp\\raw_data\\sec_filings_8k\\lulu\\8-K\\000090956...  \n",
      "4  nlp\\raw_data\\sec_filings_8k\\lulu\\8-K\\000094523...  \n",
      "       company        item  chunk_index  page_start  page_end\n",
      "count      0.0  146.000000   146.000000         0.0       0.0\n",
      "mean       NaN    4.747945     0.082192         NaN       NaN\n",
      "std        NaN    2.797217     0.462480         NaN       NaN\n",
      "min        NaN    2.020000     0.000000         NaN       NaN\n",
      "25%        NaN    2.020000     0.000000         NaN       NaN\n",
      "50%        NaN    2.020000     0.000000         NaN       NaN\n",
      "75%        NaN    8.010000     0.000000         NaN       NaN\n",
      "max        NaN    8.010000     4.000000         NaN       NaN\n",
      "                       id             report_id ticker  company        date  \\\n",
      "0  0000909567-08-001001-0  0000909567-08-001001    TXT      NaN  2008-09-11   \n",
      "1  0000909567-08-001001-1  0000909567-08-001001    TXT      NaN  2008-09-11   \n",
      "2  0000909567-08-001001-2  0000909567-08-001001    TXT      NaN  2008-09-11   \n",
      "3  0000909567-08-001001-3  0000909567-08-001001    TXT      NaN  2008-09-11   \n",
      "4  0000909567-08-001001-4  0000909567-08-001001    TXT      NaN  2008-09-11   \n",
      "\n",
      "  source doc_type item section_type section_heading  chunk_index  page_start  \\\n",
      "0    sec     10-Q    1     business        Business            0         NaN   \n",
      "1    sec     10-Q    1     business        Business            1         NaN   \n",
      "2    sec     10-Q    1     business        Business            2         NaN   \n",
      "3    sec     10-Q    1     business        Business            3         NaN   \n",
      "4    sec     10-Q    1     business        Business            4         NaN   \n",
      "\n",
      "   page_end                                               text  \\\n",
      "0       NaN  During the second quarter of fiscal 2008, foll...   \n",
      "1       NaN  During the second quarter of fiscal 2008, afte...   \n",
      "2       NaN  We believe this claim is without merit and are...   \n",
      "3       NaN  Additionally, we, or the subsidiary employing ...   \n",
      "4       NaN  Unrealized gains and losses on items\\n for whi...   \n",
      "\n",
      "                                         source_file  \n",
      "0  nlp\\raw_data\\sec_filings_10q\\lulu\\10-Q\\0000909...  \n",
      "1  nlp\\raw_data\\sec_filings_10q\\lulu\\10-Q\\0000909...  \n",
      "2  nlp\\raw_data\\sec_filings_10q\\lulu\\10-Q\\0000909...  \n",
      "3  nlp\\raw_data\\sec_filings_10q\\lulu\\10-Q\\0000909...  \n",
      "4  nlp\\raw_data\\sec_filings_10q\\lulu\\10-Q\\0000909...  \n",
      "       company  chunk_index  page_start  page_end\n",
      "count      0.0  1979.000000         0.0       0.0\n",
      "mean       NaN     2.177362         NaN       NaN\n",
      "std        NaN     1.810366         NaN       NaN\n",
      "min        NaN     0.000000         NaN       NaN\n",
      "25%        NaN     1.000000         NaN       NaN\n",
      "50%        NaN     2.000000         NaN       NaN\n",
      "75%        NaN     3.000000         NaN       NaN\n",
      "max        NaN    11.000000         NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "#Convert all csvs to dataframes\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(os.getcwd())\n",
    "atz_mda_df = pd.read_csv(\"processed_data/final/atz_mda_chunks.csv\")\n",
    "print(atz_mda_df.head())\n",
    "print(atz_mda_df.describe())\n",
    "\n",
    "yfinance_news_df = pd.read_csv(\"processed_data/final/financial_news_dataset.csv\")\n",
    "print(yfinance_news_df.head())\n",
    "print(yfinance_news_df.describe())\n",
    "\n",
    "newsapi_df = pd.read_csv(\"processed_data/final/news_data_final.csv\")\n",
    "print(newsapi_df.head())\n",
    "print(newsapi_df.describe())\n",
    "\n",
    "equity_report_df = pd.read_csv(\"processed_data/final/pdf_sections_chunks.csv\")\n",
    "print(equity_report_df.head())\n",
    "print(equity_report_df.describe())\n",
    "\n",
    "atz_press_release_df = pd.read_csv(\"processed_data/final/press_releases_chunks.csv\")\n",
    "print(atz_press_release_df.head())\n",
    "print(atz_press_release_df.describe())\n",
    "\n",
    "sec_8k_df = pd.read_csv(\"processed_data/final/sec_filings_extracted_8k.csv\")\n",
    "print(sec_8k_df.head())\n",
    "print(sec_8k_df.describe())\n",
    "\n",
    "sec_10q = pd.read_csv(\"processed_data/final/sec_filings_extracted_10q.csv\")\n",
    "print(sec_10q.head())\n",
    "print(sec_10q.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f0f5c",
   "metadata": {},
   "source": [
    "**Combine datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6c17cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] loaded pdf_sections_chunks.csv: 3178 rows\n",
      "[info] loaded atz_mda_chunks.csv: 279 rows\n",
      "[info] loaded sec_filings_extracted_10q.csv: 1979 rows\n",
      "[info] loaded sec_filings_extracted_8k.csv: 146 rows\n",
      "[info] loaded press_releases_chunks.csv: 189 rows\n",
      "[info] loaded financial_news_dataset.csv: 30 rows\n",
      "[info] loaded news_data_final.csv: 155 rows\n",
      "[done] master rows=5799 -> processed_data\\final\\master_corpus.csv\n",
      "                                                  id  \\\n",
      "0  20231103_Digital_Sales_Poised_to_Double_by_202...   \n",
      "1  20231103_Digital_Sales_Poised_to_Double_by_202...   \n",
      "2  20231103_Digital_Sales_Poised_to_Double_by_202...   \n",
      "3  20231103_Digital_Sales_Poised_to_Double_by_202...   \n",
      "4  20231103_Digital_Sales_Poised_to_Double_by_202...   \n",
      "\n",
      "                                           report_id ticker company date  \\\n",
      "0  20231103_Digital_Sales_Poised_to_Double_by_202...    ATZ     NaN  NaN   \n",
      "1  20231103_Digital_Sales_Poised_to_Double_by_202...    ATZ     NaN  NaN   \n",
      "2  20231103_Digital_Sales_Poised_to_Double_by_202...    ATZ     NaN  NaN   \n",
      "3  20231103_Digital_Sales_Poised_to_Double_by_202...    ATZ     NaN  NaN   \n",
      "4  20231103_Digital_Sales_Poised_to_Double_by_202...    ATZ     NaN  NaN   \n",
      "\n",
      "      source       doc_type item section_type  \\\n",
      "0  bloomberg  research_note  NaN       thesis   \n",
      "1  bloomberg  research_note  NaN       growth   \n",
      "2  bloomberg  research_note  NaN       growth   \n",
      "3  bloomberg  research_note  NaN       growth   \n",
      "4  bloomberg  research_note  NaN       growth   \n",
      "\n",
      "                                     section_heading chunk_index page_start  \\\n",
      "0  Aritzia Sales Could Double on US Expansion, Gr...           0          1   \n",
      "1    1. Setting Up Significant White Space Potential           1          1   \n",
      "2  Private Brands Are 95% of Sales: Wilfred 28%, ...           2          1   \n",
      "3    2. Margin Can Increase at Least 500 Bps in 2024           3          1   \n",
      "4  3. Digital Sales Poised to Double by 2027 (Cor...           4          2   \n",
      "\n",
      "  page_end                                               text  \\\n",
      "0        1  ( bloomberg intelligence ) - - aritzia has a l...   \n",
      "1        1  aritzia's plan to lift revenue 60 % to c $ 3. ...   \n",
      "2        1  26 %, super puff 7 - 8 %, denim forum, sunday ...   \n",
      "3        2  aritzia's ebitda margin could expand by 500 bp...   \n",
      "4        2  aritzia's c $ 800 million of digital sales cou...   \n",
      "\n",
      "                                         source_file  \n",
      "0  nlp\\raw_data\\bloomberg\\atz_research\\20231103_D...  \n",
      "1  nlp\\raw_data\\bloomberg\\atz_research\\20231103_D...  \n",
      "2  nlp\\raw_data\\bloomberg\\atz_research\\20231103_D...  \n",
      "3  nlp\\raw_data\\bloomberg\\atz_research\\20231103_D...  \n",
      "4  nlp\\raw_data\\bloomberg\\atz_research\\20231103_D...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "CANONICAL_FIELDS = [\n",
    "    'id', 'report_id', 'ticker', 'company', 'date', 'source', 'doc_type', 'item', 'section_type', 'section_heading', 'chunk_index', 'page_start', 'page_end', 'text', 'source_file'\n",
    "]\n",
    "\n",
    "base = Path('processed_data/final')\n",
    "data_paths = [\n",
    "    base / 'pdf_sections_chunks.csv',\n",
    "    base / 'atz_mda_chunks.csv',\n",
    "    base / 'sec_filings_extracted_10q.csv',\n",
    "    base / 'sec_filings_extracted_8k.csv',\n",
    "    base / 'press_releases_chunks.csv',\n",
    "    base / 'financial_news_dataset.csv',\n",
    "    base / 'news_data_final.csv',\n",
    "]\n",
    "\n",
    "frames = []\n",
    "for p in data_paths:\n",
    "    if not p.exists():\n",
    "        print(f'[warn] missing {p}')\n",
    "        continue\n",
    "    df = pd.read_csv(p)\n",
    "    for col in CANONICAL_FIELDS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = ''\n",
    "    df = df.reindex(columns=CANONICAL_FIELDS)\n",
    "    frames.append(df)\n",
    "    print(f'[info] loaded {p.name}: {len(df)} rows')\n",
    "\n",
    "if frames:\n",
    "    master = pd.concat(frames, ignore_index=True)\n",
    "    master = master[master['text'].astype(str).str.len() > 0]\n",
    "    master = master.drop_duplicates(subset=['text', 'source_file', 'section_heading'])\n",
    "else:\n",
    "    master = pd.DataFrame(columns=CANONICAL_FIELDS)\n",
    "\n",
    "out_path = base / 'master_corpus.csv'\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "master.to_csv(out_path, index=False)\n",
    "print(f'[done] master rows={len(master)} -> {out_path}')\n",
    "print(master.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
